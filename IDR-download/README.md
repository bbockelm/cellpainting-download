
IDR Download Tool
===================================

This directory contains tools for downloading the
contents of the IDR datasets via ftp.

The tool will create a HTCondor DAG where there is a single job per
'plate'.  The job will download the files in the plate, bundle them
into a zipfile, and then copy the resulting zipfile to a shared filesystem.

Prerequisites
=============

0.  Checkout this git repository onto a HTCondor AP.
1.  Create a "plates file", containing one line per plate you want to
    download.  A reference `plates.txt` is provided in this repo.
    
    Each line in `plates.txt` should have 3 comma-delimited columns:
    - The first column is the IDR study identifier (eg idr0003)
    - The second column is the FTP file server path, relative to `ftp.ebi.ac.uk/pub/databases/IDR` (eg `idr0003-breker-plasticity/201301120/Images/DTT/p11`)
    - The third column is the plate name (eg plate_3A)

    Note: there will be one HTCondor job per line in this file.
2.  The submitted DAG will need authorization tokens that are currently not generated by default. As a workaround
    we can submit a sleeper job that does this for us. To do this, run:
    `condor_submit scitokens-workaround.sub`

Running the Download Tool
=========================

To run the tool, invoke the `IDR-download` script:

```
./IDR-download submit --max-running 15 --plates plates.txt --destination /staging/groups/caicedo_group/morphem/
```

The command-line options are:

- `--destination`: The destination directory for the zip'd measurement files.  This must be mounted on the worker nodes.
- `--working-dir`: A directory name for the state files and debugging info for the jobs.
- `--instance`: An instance name for the run.
- `--max-running`: The maximum number of running downloads.  Many filesystems can't manage an unbounded number of
  transfers; use `max-running` to avoid overloads.  A good value of `--max-running` would be 30.

